{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoML-FLAML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBqHhE+0C1EXGKKV3SiIKx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApahSaroj/WQC/blob/main/AutoML_FLAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSaGF3gd0n3m"
      },
      "source": [
        "https://github.com/microsoft/FLAML/blob/main/notebook/flaml_automl.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiMaAgzDwLz_",
        "outputId": "f76de682-e3f9-4ace-b990-b3623a04a8a7"
      },
      "source": [
        "pip install flaml[notebook];"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flaml[notebook] in /usr/local/lib/python3.7/dist-packages (0.5.10)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.19.5)\n",
            "Requirement already satisfied: catboost>=0.23 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.26)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.24.2)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.2.1)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.90)\n",
            "Requirement already satisfied: vowpalwabbit in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (8.11.0)\n",
            "Requirement already satisfied: rgf-python in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.10.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.0.0)\n",
            "Requirement already satisfied: matplotlib==3.2.0 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.2.0)\n",
            "Requirement already satisfied: openml==0.10.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.10.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (2.8.1)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (0.12.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (1.1.5)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (2.23.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml[notebook]) (0.36.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->openml==0.10.2->flaml[notebook]) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->flaml[notebook]) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->flaml[notebook]) (2.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.1.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (7.6.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.5.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.1.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.0.5)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.3.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (57.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel->jupyter->flaml[notebook]) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (5.1.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]) (2.6.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (1.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->flaml[notebook]) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->flaml[notebook]) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->flaml[notebook]) (2.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]) (21.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]) (0.5.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.23->flaml[notebook]) (1.3.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->flaml[notebook]) (1.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LMEP4wB6DLM"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yNBe7EG7a0t",
        "outputId": "c4059b3f-fbf7-4954-c0c0-6405f0754cfc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6uU8XO897dcF",
        "outputId": "f6a9939c-9024-4d45-c69c-0c6b4c8e567e"
      },
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/DATA/WQC_test.xlsx')\n",
        "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "df.drop(df.columns[df.columns.str.contains('WPI',case = False)],axis = 1, inplace = True)\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pH</th>\n",
              "      <th>DO</th>\n",
              "      <th>TDS</th>\n",
              "      <th>Alkalinity</th>\n",
              "      <th>EC</th>\n",
              "      <th>Na</th>\n",
              "      <th>Ca</th>\n",
              "      <th>Mg</th>\n",
              "      <th>K</th>\n",
              "      <th>F</th>\n",
              "      <th>Cl</th>\n",
              "      <th>Nitrate</th>\n",
              "      <th>Sulphate</th>\n",
              "      <th>Phosphate</th>\n",
              "      <th>WQC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.14</td>\n",
              "      <td>8.7</td>\n",
              "      <td>84.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>147.8</td>\n",
              "      <td>4.48</td>\n",
              "      <td>44.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.285</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.758000</td>\n",
              "      <td>6.534660</td>\n",
              "      <td>0.06211</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.70</td>\n",
              "      <td>8.8</td>\n",
              "      <td>110.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>8.61</td>\n",
              "      <td>44.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>3.46</td>\n",
              "      <td>0.401</td>\n",
              "      <td>14.80</td>\n",
              "      <td>0.196062</td>\n",
              "      <td>8.138620</td>\n",
              "      <td>0.00960</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.60</td>\n",
              "      <td>7.5</td>\n",
              "      <td>75.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>8.11</td>\n",
              "      <td>28.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>0.379</td>\n",
              "      <td>14.80</td>\n",
              "      <td>0.298875</td>\n",
              "      <td>3.855625</td>\n",
              "      <td>0.01280</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.20</td>\n",
              "      <td>9.1</td>\n",
              "      <td>76.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>6.30</td>\n",
              "      <td>44.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.396</td>\n",
              "      <td>9.60</td>\n",
              "      <td>0.299590</td>\n",
              "      <td>2.238750</td>\n",
              "      <td>0.01536</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.31</td>\n",
              "      <td>7.3</td>\n",
              "      <td>84.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>5.50</td>\n",
              "      <td>28.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.61</td>\n",
              "      <td>0.265</td>\n",
              "      <td>8.30</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>7.60</td>\n",
              "      <td>5.6</td>\n",
              "      <td>224.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>370.0</td>\n",
              "      <td>16.14</td>\n",
              "      <td>92.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>7.60</td>\n",
              "      <td>2.270</td>\n",
              "      <td>23.04</td>\n",
              "      <td>1.352000</td>\n",
              "      <td>104.480000</td>\n",
              "      <td>0.01500</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>7.30</td>\n",
              "      <td>5.6</td>\n",
              "      <td>266.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>20.56</td>\n",
              "      <td>96.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>9.89</td>\n",
              "      <td>1.550</td>\n",
              "      <td>30.86</td>\n",
              "      <td>7.074000</td>\n",
              "      <td>61.068000</td>\n",
              "      <td>0.03300</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>5.10</td>\n",
              "      <td>5.8</td>\n",
              "      <td>290.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>487.0</td>\n",
              "      <td>37.35</td>\n",
              "      <td>60.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>14.80</td>\n",
              "      <td>0.159</td>\n",
              "      <td>60.13</td>\n",
              "      <td>9.256000</td>\n",
              "      <td>89.910000</td>\n",
              "      <td>0.16300</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>7.40</td>\n",
              "      <td>6.4</td>\n",
              "      <td>230.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>385.0</td>\n",
              "      <td>20.06</td>\n",
              "      <td>70.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>10.35</td>\n",
              "      <td>1.360</td>\n",
              "      <td>32.92</td>\n",
              "      <td>7.110435</td>\n",
              "      <td>48.500000</td>\n",
              "      <td>0.21900</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>7.60</td>\n",
              "      <td>6.9</td>\n",
              "      <td>243.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>410.8</td>\n",
              "      <td>17.41</td>\n",
              "      <td>82.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>9.92</td>\n",
              "      <td>1.310</td>\n",
              "      <td>34.89</td>\n",
              "      <td>6.385000</td>\n",
              "      <td>59.940000</td>\n",
              "      <td>0.07000</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>487 rows Ã— 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pH   DO    TDS  Alkalinity  ...   Nitrate    Sulphate  Phosphate        WQC\n",
              "0    8.14  8.7   84.0        52.0  ...  0.758000    6.534660    0.06211  Excellent\n",
              "1    7.70  8.8  110.0        76.0  ...  0.196062    8.138620    0.00960  Excellent\n",
              "2    7.60  7.5   75.0        44.0  ...  0.298875    3.855625    0.01280  Excellent\n",
              "3    8.20  9.1   76.0        56.0  ...  0.299590    2.238750    0.01536  Excellent\n",
              "4    7.31  7.3   84.0        52.0  ...  0.106000    5.600000    0.01000  Excellent\n",
              "..    ...  ...    ...         ...  ...       ...         ...        ...        ...\n",
              "482  7.60  5.6  224.0         8.0  ...  1.352000  104.480000    0.01500  Excellent\n",
              "483  7.30  5.6  266.0        96.0  ...  7.074000   61.068000    0.03300  Excellent\n",
              "484  5.10  5.8  290.0        12.0  ...  9.256000   89.910000    0.16300  Excellent\n",
              "485  7.40  6.4  230.0        72.0  ...  7.110435   48.500000    0.21900       Good\n",
              "486  7.60  6.9  243.0        68.0  ...  6.385000   59.940000    0.07000  Excellent\n",
              "\n",
              "[487 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xd2OEpaCphH",
        "outputId": "a73b5039-c36a-411d-a60c-2b3d9fed8714"
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pH            0\n",
            "DO            0\n",
            "TDS           0\n",
            "Alkalinity    0\n",
            "EC            0\n",
            "Na            0\n",
            "Ca            0\n",
            "Mg            0\n",
            "K             0\n",
            "F             0\n",
            "Cl            0\n",
            "Nitrate       0\n",
            "Sulphate      0\n",
            "Phosphate     2\n",
            "WQC           0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxwMwAmVDJGM"
      },
      "source": [
        "df = df.dropna()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0UgsxXJ-q4k",
        "outputId": "0cd12a3a-c731-4d8b-e188-b8302c2a9912"
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pH            0\n",
            "DO            0\n",
            "TDS           0\n",
            "Alkalinity    0\n",
            "EC            0\n",
            "Na            0\n",
            "Ca            0\n",
            "Mg            0\n",
            "K             0\n",
            "F             0\n",
            "Cl            0\n",
            "Nitrate       0\n",
            "Sulphate      0\n",
            "Phosphate     0\n",
            "WQC           0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ4K4QORwGjT",
        "outputId": "162bf24f-7936-479f-f60b-845fe3ba3fb3"
      },
      "source": [
        "# Taking  all rows and all columns in the data except the last column as X (feature matrix)\n",
        "#the row numbers and customer id's are not necessary for the modelling so we get rid of and start with credit score\n",
        "X = df.iloc[:,0:-1].values\n",
        "print(\"Independent variables are:\", X)\n",
        "#taking all rows but only the last column as Y(dependent variable)\n",
        "y = df.iloc[:, -1].values\n",
        "print(\"Dependent variable is:\", y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Independent variables are: [[8.1400000e+00 8.7000000e+00 8.4000000e+01 ... 7.5800000e-01\n",
            "  6.5346600e+00 6.2110500e-02]\n",
            " [7.7000000e+00 8.8000000e+00 1.1000000e+02 ... 1.9606200e-01\n",
            "  8.1386200e+00 9.6000000e-03]\n",
            " [7.6000000e+00 7.5000000e+00 7.5000000e+01 ... 2.9887500e-01\n",
            "  3.8556250e+00 1.2800000e-02]\n",
            " ...\n",
            " [5.1000000e+00 5.8000000e+00 2.9000000e+02 ... 9.2560000e+00\n",
            "  8.9910000e+01 1.6300000e-01]\n",
            " [7.4000000e+00 6.4000000e+00 2.3000000e+02 ... 7.1104355e+00\n",
            "  4.8500000e+01 2.1900000e-01]\n",
            " [7.6000000e+00 6.9000000e+00 2.4300000e+02 ... 6.3850000e+00\n",
            "  5.9940000e+01 7.0000000e-02]]\n",
            "Dependent variable is: ['Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Good' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Good' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Good' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'moderately polluted water' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Good' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Good' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'moderately polluted water' 'Good' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Good' 'Excellent' 'highly polluted water' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Good' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'moderately polluted water' 'Good' 'Excellent' 'Excellent'\n",
            " 'moderately polluted water' 'moderately polluted water' 'Excellent'\n",
            " 'Excellent' 'Good' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Good'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'moderately polluted water' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'highly polluted water' 'Excellent' 'moderately polluted water' 'Good'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Good' 'Excellent' 'Excellent' 'Good' 'Excellent'\n",
            " 'Good' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Good' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Good' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Good' 'Excellent']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm6AMoQGw-hH",
        "outputId": "2f446663-ce18-4b37-f1d0-9d303397451a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Splitting the data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "#printing the dimensions of each of those snapshots to see amount of rows and columns i each of them\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(388, 14) (97, 14)\n",
            "(388,) (97,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXV3BCxBwhT4"
      },
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoF7R-Vpwnc7"
      },
      "source": [
        "settings = {\n",
        "    \"time_budget\": 300,  # total running time in seconds\n",
        "    \"metric\": 'accuracy',  # primary metrics can be chosen from: ['accuracy','roc_auc','f1','log_loss','mae','mse','r2']\n",
        "    \"task\": 'classification',  # task type    \n",
        "}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5qLUekpwrdF",
        "outputId": "50c32ca9-09e1-478f-fc1c-e268ce9f0537"
      },
      "source": [
        "automl.fit(X_train=X_train, y_train=y_train, **settings)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[flaml.automl: 08-01 03:31:58] {913} INFO - Evaluation method: cv\n",
            "[flaml.automl: 08-01 03:31:58] {509} INFO - class 1 augmented from 16 to 32\n",
            "[flaml.automl: 08-01 03:31:58] {509} INFO - class 2 augmented from 1 to 20\n",
            "[flaml.automl: 08-01 03:31:58] {509} INFO - class 3 augmented from 3 to 21\n",
            "[flaml.automl: 08-01 03:31:58] {607} INFO - Using StratifiedKFold\n",
            "[flaml.automl: 08-01 03:31:58] {934} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 08-01 03:31:58] {954} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
            "[flaml.automl: 08-01 03:31:58] {1020} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 08-01 03:31:58] {1180} INFO -  at 0.1s,\tbest lgbm's error=0.1655,\tbest lgbm's error=0.1655\n",
            "[flaml.automl: 08-01 03:31:58] {1020} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 08-01 03:31:58] {1180} INFO -  at 0.2s,\tbest lgbm's error=0.1655,\tbest lgbm's error=0.1655\n",
            "[flaml.automl: 08-01 03:31:58] {1020} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 08-01 03:31:58] {1180} INFO -  at 0.2s,\tbest lgbm's error=0.0340,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:31:58] {1020} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 08-01 03:31:58] {1180} INFO -  at 0.3s,\tbest lgbm's error=0.0340,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:31:58] {1020} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 08-01 03:31:58] {1180} INFO -  at 0.3s,\tbest lgbm's error=0.0340,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:31:58] {1020} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 08-01 03:31:58] {1180} INFO -  at 0.4s,\tbest lgbm's error=0.0340,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:31:58] {1020} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl: 08-01 03:31:59] {1180} INFO -  at 0.5s,\tbest xgboost's error=0.0409,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:31:59] {1020} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 08-01 03:31:59] {1180} INFO -  at 0.5s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:31:59] {1020} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 08-01 03:31:59] {1180} INFO -  at 0.6s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:31:59] {1020} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl: 08-01 03:31:59] {1180} INFO -  at 0.7s,\tbest xgboost's error=0.0409,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:31:59] {1020} INFO - iteration 10, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:32:00] {1180} INFO -  at 1.8s,\tbest extra_tree's error=0.0748,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:32:00] {1020} INFO - iteration 11, current learner rf\n",
            "[flaml.automl: 08-01 03:32:01] {1180} INFO -  at 3.0s,\tbest rf's error=0.0499,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:32:01] {1020} INFO - iteration 12, current learner rf\n",
            "[flaml.automl: 08-01 03:32:02] {1180} INFO -  at 4.1s,\tbest rf's error=0.0477,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:32:02] {1020} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:02] {1180} INFO -  at 4.2s,\tbest xgboost's error=0.0318,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:32:02] {1020} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 08-01 03:32:02] {1180} INFO -  at 4.2s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:32:02] {1020} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:02] {1180} INFO -  at 4.3s,\tbest xgboost's error=0.0227,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:32:02] {1020} INFO - iteration 16, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 4.4s,\tbest xgboost's error=0.0159,\tbest xgboost's error=0.0159\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 4.5s,\tbest xgboost's error=0.0159,\tbest xgboost's error=0.0159\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 4.6s,\tbest lgbm's error=0.0182,\tbest xgboost's error=0.0159\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 4.7s,\tbest xgboost's error=0.0159,\tbest xgboost's error=0.0159\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 4.7s,\tbest lgbm's error=0.0182,\tbest xgboost's error=0.0159\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 4.8s,\tbest xgboost's error=0.0068,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 4.9s,\tbest lgbm's error=0.0182,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 5.0s,\tbest lgbm's error=0.0182,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:03] {1180} INFO -  at 5.0s,\tbest xgboost's error=0.0068,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:32:03] {1020} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:32:04] {1180} INFO -  at 6.2s,\tbest extra_tree's error=0.0476,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:32:04] {1020} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:04] {1180} INFO -  at 6.3s,\tbest xgboost's error=0.0068,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:32:04] {1020} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 6.4s,\tbest xgboost's error=0.0068,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 6.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 6.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 6.6s,\tbest lgbm's error=0.0182,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 6.7s,\tbest lgbm's error=0.0182,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 32, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 6.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 6.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 7.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:05] {1180} INFO -  at 7.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:05] {1020} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:32:06] {1180} INFO -  at 8.2s,\tbest extra_tree's error=0.0476,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:06] {1020} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:06] {1180} INFO -  at 8.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:06] {1020} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:07] {1180} INFO -  at 8.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:07] {1020} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:07] {1180} INFO -  at 8.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:07] {1020} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:07] {1180} INFO -  at 8.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:07] {1020} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:07] {1180} INFO -  at 8.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:07] {1020} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:07] {1180} INFO -  at 8.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:07] {1020} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:07] {1180} INFO -  at 8.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:07] {1020} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:32:08] {1180} INFO -  at 10.1s,\tbest extra_tree's error=0.0476,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:08] {1020} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:08] {1180} INFO -  at 10.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:08] {1020} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:08] {1180} INFO -  at 10.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:08] {1020} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:09] {1180} INFO -  at 10.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:09] {1020} INFO - iteration 48, current learner catboost\n",
            "[flaml.automl: 08-01 03:32:36] {1180} INFO -  at 37.8s,\tbest catboost's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:36] {1020} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:36] {1180} INFO -  at 37.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:36] {1020} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:36] {1180} INFO -  at 38.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:36] {1020} INFO - iteration 51, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:32:37] {1180} INFO -  at 39.1s,\tbest extra_tree's error=0.0363,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:37] {1020} INFO - iteration 52, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:37] {1180} INFO -  at 39.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:37] {1020} INFO - iteration 53, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:37] {1180} INFO -  at 39.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:37] {1020} INFO - iteration 54, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:38] {1180} INFO -  at 39.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:38] {1020} INFO - iteration 55, current learner rf\n",
            "[flaml.automl: 08-01 03:32:39] {1180} INFO -  at 40.6s,\tbest rf's error=0.0477,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:39] {1020} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:39] {1180} INFO -  at 40.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:39] {1020} INFO - iteration 57, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:39] {1180} INFO -  at 40.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:39] {1020} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:39] {1180} INFO -  at 40.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:39] {1020} INFO - iteration 59, current learner xgboost\n",
            "[flaml.automl: 08-01 03:32:39] {1180} INFO -  at 41.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:32:39] {1020} INFO - iteration 60, current learner catboost\n",
            "[flaml.automl: 08-01 03:33:10] {1180} INFO -  at 72.0s,\tbest catboost's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:10] {1020} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:10] {1180} INFO -  at 72.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:10] {1020} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:10] {1180} INFO -  at 72.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:10] {1020} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:10] {1180} INFO -  at 72.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:10] {1020} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:10] {1180} INFO -  at 72.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:10] {1020} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:11] {1180} INFO -  at 72.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:11] {1020} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:11] {1180} INFO -  at 72.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:11] {1020} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:11] {1180} INFO -  at 72.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:11] {1020} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:11] {1180} INFO -  at 72.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:11] {1020} INFO - iteration 69, current learner catboost\n",
            "[flaml.automl: 08-01 03:33:34] {1180} INFO -  at 96.2s,\tbest catboost's error=0.0091,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:34] {1020} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:34] {1180} INFO -  at 96.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:34] {1020} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:34] {1180} INFO -  at 96.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:34] {1020} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:35] {1180} INFO -  at 96.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:35] {1020} INFO - iteration 73, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:36] {1180} INFO -  at 97.7s,\tbest extra_tree's error=0.0363,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:36] {1020} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:36] {1180} INFO -  at 97.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:36] {1020} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:36] {1180} INFO -  at 97.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:36] {1020} INFO - iteration 76, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:36] {1180} INFO -  at 98.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:36] {1020} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:36] {1180} INFO -  at 98.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:36] {1020} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:36] {1180} INFO -  at 98.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:36] {1020} INFO - iteration 79, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:36] {1180} INFO -  at 98.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:36] {1020} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:36] {1180} INFO -  at 98.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:36] {1020} INFO - iteration 81, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:38] {1180} INFO -  at 99.5s,\tbest extra_tree's error=0.0250,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:38] {1020} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:38] {1180} INFO -  at 99.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:38] {1020} INFO - iteration 83, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:39] {1180} INFO -  at 100.8s,\tbest extra_tree's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:39] {1020} INFO - iteration 84, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:40] {1180} INFO -  at 102.0s,\tbest extra_tree's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:40] {1020} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:41] {1180} INFO -  at 103.2s,\tbest extra_tree's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:41] {1020} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:41] {1180} INFO -  at 103.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:41] {1020} INFO - iteration 87, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:43] {1180} INFO -  at 104.6s,\tbest extra_tree's error=0.0113,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:43] {1020} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:43] {1180} INFO -  at 104.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:43] {1020} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:43] {1180} INFO -  at 104.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:43] {1020} INFO - iteration 90, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:44] {1180} INFO -  at 106.0s,\tbest extra_tree's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:44] {1020} INFO - iteration 91, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:45] {1180} INFO -  at 107.3s,\tbest extra_tree's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:45] {1020} INFO - iteration 92, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:47] {1180} INFO -  at 108.5s,\tbest extra_tree's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:47] {1020} INFO - iteration 93, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:48] {1180} INFO -  at 109.7s,\tbest extra_tree's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:48] {1020} INFO - iteration 94, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:49] {1180} INFO -  at 110.9s,\tbest extra_tree's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:49] {1020} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:49] {1180} INFO -  at 110.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:49] {1020} INFO - iteration 96, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:50] {1180} INFO -  at 112.2s,\tbest extra_tree's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:50] {1020} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:50] {1180} INFO -  at 112.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:50] {1020} INFO - iteration 98, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:51] {1180} INFO -  at 112.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:51] {1020} INFO - iteration 99, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:51] {1180} INFO -  at 112.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:51] {1020} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:51] {1180} INFO -  at 112.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:51] {1020} INFO - iteration 101, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:52] {1180} INFO -  at 113.7s,\tbest extra_tree's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:52] {1020} INFO - iteration 102, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:52] {1180} INFO -  at 113.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:52] {1020} INFO - iteration 103, current learner lgbm\n",
            "[flaml.automl: 08-01 03:33:52] {1180} INFO -  at 113.9s,\tbest lgbm's error=0.0182,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:52] {1020} INFO - iteration 104, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:52] {1180} INFO -  at 114.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:52] {1020} INFO - iteration 105, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:52] {1180} INFO -  at 114.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:52] {1020} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 08-01 03:33:52] {1180} INFO -  at 114.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:33:52] {1020} INFO - iteration 107, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:54] {1180} INFO -  at 115.7s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:33:54] {1020} INFO - iteration 108, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:55] {1180} INFO -  at 117.0s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:33:55] {1020} INFO - iteration 109, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:56] {1180} INFO -  at 118.3s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:33:56] {1020} INFO - iteration 110, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:33:58] {1180} INFO -  at 119.5s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:33:58] {1020} INFO - iteration 111, current learner rf\n",
            "[flaml.automl: 08-01 03:33:59] {1180} INFO -  at 120.8s,\tbest rf's error=0.0431,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:33:59] {1020} INFO - iteration 112, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:00] {1180} INFO -  at 122.0s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:00] {1020} INFO - iteration 113, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:01] {1180} INFO -  at 123.3s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:01] {1020} INFO - iteration 114, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:03] {1180} INFO -  at 124.6s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:03] {1020} INFO - iteration 115, current learner catboost\n",
            "[flaml.automl: 08-01 03:34:26] {1180} INFO -  at 147.8s,\tbest catboost's error=0.0091,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:26] {1020} INFO - iteration 116, current learner rf\n",
            "[flaml.automl: 08-01 03:34:27] {1180} INFO -  at 148.9s,\tbest rf's error=0.0341,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:27] {1020} INFO - iteration 117, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:28] {1180} INFO -  at 150.2s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:28] {1020} INFO - iteration 118, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:30] {1180} INFO -  at 151.5s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:30] {1020} INFO - iteration 119, current learner rf\n",
            "[flaml.automl: 08-01 03:34:31] {1180} INFO -  at 152.7s,\tbest rf's error=0.0341,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:31] {1020} INFO - iteration 120, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:32] {1180} INFO -  at 154.0s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:32] {1020} INFO - iteration 121, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:33] {1180} INFO -  at 155.3s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:33] {1020} INFO - iteration 122, current learner lrl1\n",
            "No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:34] {1180} INFO -  at 155.8s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:34] {1020} INFO - iteration 123, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:34] {1180} INFO -  at 156.3s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:34] {1020} INFO - iteration 124, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:35] {1180} INFO -  at 156.8s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:35] {1020} INFO - iteration 125, current learner rf\n",
            "[flaml.automl: 08-01 03:34:36] {1180} INFO -  at 158.0s,\tbest rf's error=0.0227,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:36] {1020} INFO - iteration 126, current learner rf\n",
            "[flaml.automl: 08-01 03:34:37] {1180} INFO -  at 159.3s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:37] {1020} INFO - iteration 127, current learner rf\n",
            "[flaml.automl: 08-01 03:34:39] {1180} INFO -  at 160.4s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:39] {1020} INFO - iteration 128, current learner rf\n",
            "[flaml.automl: 08-01 03:34:40] {1180} INFO -  at 161.7s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:40] {1020} INFO - iteration 129, current learner rf\n",
            "[flaml.automl: 08-01 03:34:41] {1180} INFO -  at 162.9s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:41] {1020} INFO - iteration 130, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:42] {1180} INFO -  at 163.5s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:42] {1020} INFO - iteration 131, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:43] {1180} INFO -  at 164.7s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:43] {1020} INFO - iteration 132, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:44] {1180} INFO -  at 166.0s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:44] {1020} INFO - iteration 133, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:45] {1180} INFO -  at 166.5s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:45] {1020} INFO - iteration 134, current learner rf\n",
            "[flaml.automl: 08-01 03:34:46] {1180} INFO -  at 167.8s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:46] {1020} INFO - iteration 135, current learner rf\n",
            "[flaml.automl: 08-01 03:34:47] {1180} INFO -  at 169.0s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:47] {1020} INFO - iteration 136, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:48] {1180} INFO -  at 169.6s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:48] {1020} INFO - iteration 137, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:48] {1180} INFO -  at 170.1s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:48] {1020} INFO - iteration 138, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:50] {1180} INFO -  at 171.4s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:50] {1020} INFO - iteration 139, current learner rf\n",
            "[flaml.automl: 08-01 03:34:51] {1180} INFO -  at 172.5s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:51] {1020} INFO - iteration 140, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:51] {1180} INFO -  at 173.1s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:51] {1020} INFO - iteration 141, current learner rf\n",
            "[flaml.automl: 08-01 03:34:52] {1180} INFO -  at 174.3s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:52] {1020} INFO - iteration 142, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:53] {1180} INFO -  at 174.9s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:53] {1020} INFO - iteration 143, current learner rf\n",
            "[flaml.automl: 08-01 03:34:54] {1180} INFO -  at 176.1s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:54] {1020} INFO - iteration 144, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:55] {1180} INFO -  at 176.6s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:55] {1020} INFO - iteration 145, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:34:55] {1180} INFO -  at 177.2s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:55] {1020} INFO - iteration 146, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:34:57] {1180} INFO -  at 178.4s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:57] {1020} INFO - iteration 147, current learner rf\n",
            "[flaml.automl: 08-01 03:34:58] {1180} INFO -  at 179.7s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:58] {1020} INFO - iteration 148, current learner rf\n",
            "[flaml.automl: 08-01 03:34:59] {1180} INFO -  at 180.9s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:34:59] {1020} INFO - iteration 149, current learner rf\n",
            "[flaml.automl: 08-01 03:35:00] {1180} INFO -  at 182.2s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:00] {1020} INFO - iteration 150, current learner rf\n",
            "[flaml.automl: 08-01 03:35:02] {1180} INFO -  at 183.5s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:02] {1020} INFO - iteration 151, current learner rf\n",
            "[flaml.automl: 08-01 03:35:03] {1180} INFO -  at 184.8s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:03] {1020} INFO - iteration 152, current learner rf\n",
            "[flaml.automl: 08-01 03:35:04] {1180} INFO -  at 186.0s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:04] {1020} INFO - iteration 153, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:05] {1180} INFO -  at 186.6s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:05] {1020} INFO - iteration 154, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:06] {1180} INFO -  at 187.8s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:06] {1020} INFO - iteration 155, current learner rf\n",
            "[flaml.automl: 08-01 03:35:07] {1180} INFO -  at 189.1s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:07] {1020} INFO - iteration 156, current learner rf\n",
            "[flaml.automl: 08-01 03:35:08] {1180} INFO -  at 190.4s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:08] {1020} INFO - iteration 157, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:09] {1180} INFO -  at 190.9s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:09] {1020} INFO - iteration 158, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:10] {1180} INFO -  at 192.1s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:10] {1020} INFO - iteration 159, current learner rf\n",
            "[flaml.automl: 08-01 03:35:12] {1180} INFO -  at 193.4s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:12] {1020} INFO - iteration 160, current learner rf\n",
            "[flaml.automl: 08-01 03:35:13] {1180} INFO -  at 194.7s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:13] {1020} INFO - iteration 161, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:13] {1180} INFO -  at 195.2s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:13] {1020} INFO - iteration 162, current learner rf\n",
            "[flaml.automl: 08-01 03:35:15] {1180} INFO -  at 196.5s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:15] {1020} INFO - iteration 163, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:16] {1180} INFO -  at 197.7s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:16] {1020} INFO - iteration 164, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:16] {1180} INFO -  at 198.3s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:16] {1020} INFO - iteration 165, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:17] {1180} INFO -  at 198.8s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:17] {1020} INFO - iteration 166, current learner rf\n",
            "[flaml.automl: 08-01 03:35:18] {1180} INFO -  at 200.0s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:18] {1020} INFO - iteration 167, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:19] {1180} INFO -  at 201.2s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:19] {1020} INFO - iteration 168, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:20] {1180} INFO -  at 201.7s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:20] {1020} INFO - iteration 169, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:20] {1180} INFO -  at 202.3s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:20] {1020} INFO - iteration 170, current learner rf\n",
            "[flaml.automl: 08-01 03:35:22] {1180} INFO -  at 203.5s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:22] {1020} INFO - iteration 171, current learner rf\n",
            "[flaml.automl: 08-01 03:35:23] {1180} INFO -  at 204.8s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:23] {1020} INFO - iteration 172, current learner rf\n",
            "[flaml.automl: 08-01 03:35:24] {1180} INFO -  at 206.1s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:24] {1020} INFO - iteration 173, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:25] {1180} INFO -  at 207.3s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:25] {1020} INFO - iteration 174, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:27] {1180} INFO -  at 208.6s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:27] {1020} INFO - iteration 175, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:28] {1180} INFO -  at 209.9s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:28] {1020} INFO - iteration 176, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:29] {1180} INFO -  at 211.1s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:29] {1020} INFO - iteration 177, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:30] {1180} INFO -  at 211.6s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:30] {1020} INFO - iteration 178, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:31] {1180} INFO -  at 212.9s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:31] {1020} INFO - iteration 179, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:32] {1180} INFO -  at 214.2s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:32] {1020} INFO - iteration 180, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:34] {1180} INFO -  at 215.4s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:34] {1020} INFO - iteration 181, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:34] {1180} INFO -  at 216.0s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:34] {1020} INFO - iteration 182, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:35] {1180} INFO -  at 216.5s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:35] {1020} INFO - iteration 183, current learner rf\n",
            "[flaml.automl: 08-01 03:35:36] {1180} INFO -  at 217.8s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:36] {1020} INFO - iteration 184, current learner rf\n",
            "[flaml.automl: 08-01 03:35:37] {1180} INFO -  at 219.0s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:37] {1020} INFO - iteration 185, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:38] {1180} INFO -  at 220.3s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:38] {1020} INFO - iteration 186, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:39] {1180} INFO -  at 220.8s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:39] {1020} INFO - iteration 187, current learner rf\n",
            "[flaml.automl: 08-01 03:35:40] {1180} INFO -  at 222.1s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:40] {1020} INFO - iteration 188, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:41] {1180} INFO -  at 222.6s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:41] {1020} INFO - iteration 189, current learner rf\n",
            "[flaml.automl: 08-01 03:35:42] {1180} INFO -  at 223.9s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:42] {1020} INFO - iteration 190, current learner rf\n",
            "[flaml.automl: 08-01 03:35:43] {1180} INFO -  at 225.1s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:43] {1020} INFO - iteration 191, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:44] {1180} INFO -  at 225.7s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:44] {1020} INFO - iteration 192, current learner rf\n",
            "[flaml.automl: 08-01 03:35:45] {1180} INFO -  at 226.9s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:45] {1020} INFO - iteration 193, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:46] {1180} INFO -  at 227.5s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:46] {1020} INFO - iteration 194, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:47] {1180} INFO -  at 228.7s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:47] {1020} INFO - iteration 195, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:47] {1180} INFO -  at 229.2s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:47] {1020} INFO - iteration 196, current learner rf\n",
            "[flaml.automl: 08-01 03:35:49] {1180} INFO -  at 230.5s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:49] {1020} INFO - iteration 197, current learner rf\n",
            "[flaml.automl: 08-01 03:35:50] {1180} INFO -  at 231.8s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:50] {1020} INFO - iteration 198, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:50] {1180} INFO -  at 232.3s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:50] {1020} INFO - iteration 199, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:51] {1180} INFO -  at 232.8s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:51] {1020} INFO - iteration 200, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:51] {1180} INFO -  at 233.3s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:51] {1020} INFO - iteration 201, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:52] {1180} INFO -  at 233.9s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:52] {1020} INFO - iteration 202, current learner lgbm\n",
            "[flaml.automl: 08-01 03:35:52] {1180} INFO -  at 234.0s,\tbest lgbm's error=0.0182,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:52] {1020} INFO - iteration 203, current learner rf\n",
            "[flaml.automl: 08-01 03:35:53] {1180} INFO -  at 235.2s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:53] {1020} INFO - iteration 204, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:55] {1180} INFO -  at 236.5s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:55] {1020} INFO - iteration 205, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:55] {1180} INFO -  at 237.0s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:55] {1020} INFO - iteration 206, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:56] {1180} INFO -  at 237.6s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:56] {1020} INFO - iteration 207, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:57] {1180} INFO -  at 238.8s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:57] {1020} INFO - iteration 208, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:35:57] {1180} INFO -  at 239.3s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:57] {1020} INFO - iteration 209, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:35:59] {1180} INFO -  at 240.6s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:35:59] {1020} INFO - iteration 210, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:00] {1180} INFO -  at 241.9s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:00] {1020} INFO - iteration 211, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:01] {1180} INFO -  at 243.1s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:01] {1020} INFO - iteration 212, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:03] {1180} INFO -  at 244.4s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:03] {1020} INFO - iteration 213, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:04] {1180} INFO -  at 245.7s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:04] {1020} INFO - iteration 214, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:04] {1180} INFO -  at 246.2s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:04] {1020} INFO - iteration 215, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:05] {1180} INFO -  at 246.7s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:05] {1020} INFO - iteration 216, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:06] {1180} INFO -  at 248.0s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:06] {1020} INFO - iteration 217, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:07] {1180} INFO -  at 248.5s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:07] {1020} INFO - iteration 218, current learner rf\n",
            "[flaml.automl: 08-01 03:36:08] {1180} INFO -  at 249.8s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:08] {1020} INFO - iteration 219, current learner rf\n",
            "[flaml.automl: 08-01 03:36:09] {1180} INFO -  at 251.0s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:09] {1020} INFO - iteration 220, current learner rf\n",
            "[flaml.automl: 08-01 03:36:11] {1180} INFO -  at 252.4s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:11] {1020} INFO - iteration 221, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:12] {1180} INFO -  at 253.7s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:12] {1020} INFO - iteration 222, current learner rf\n",
            "[flaml.automl: 08-01 03:36:13] {1180} INFO -  at 254.9s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:13] {1020} INFO - iteration 223, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:14] {1180} INFO -  at 255.5s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:14] {1020} INFO - iteration 224, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:14] {1180} INFO -  at 256.0s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:14] {1020} INFO - iteration 225, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:14] {1180} INFO -  at 256.1s,\tbest lgbm's error=0.0182,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:14] {1020} INFO - iteration 226, current learner rf\n",
            "[flaml.automl: 08-01 03:36:15] {1180} INFO -  at 257.3s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:15] {1020} INFO - iteration 227, current learner catboost\n",
            "[flaml.automl: 08-01 03:36:24] {1180} INFO -  at 265.8s,\tbest catboost's error=0.0091,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:24] {1020} INFO - iteration 228, current learner rf\n",
            "[flaml.automl: 08-01 03:36:25] {1180} INFO -  at 267.0s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:25] {1020} INFO - iteration 229, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:26] {1180} INFO -  at 267.6s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:26] {1020} INFO - iteration 230, current learner catboost\n",
            "[flaml.automl: 08-01 03:36:35] {1180} INFO -  at 277.3s,\tbest catboost's error=0.0091,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:35] {1020} INFO - iteration 231, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:36] {1180} INFO -  at 277.9s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:36] {1020} INFO - iteration 232, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:37] {1180} INFO -  at 279.1s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:37] {1020} INFO - iteration 233, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:38] {1180} INFO -  at 279.6s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:38] {1020} INFO - iteration 234, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:38] {1180} INFO -  at 280.2s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:38] {1020} INFO - iteration 235, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:39] {1180} INFO -  at 280.7s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:39] {1020} INFO - iteration 236, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:40] {1180} INFO -  at 282.0s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:40] {1020} INFO - iteration 237, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:41] {1180} INFO -  at 283.2s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:41] {1020} INFO - iteration 238, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:42] {1180} INFO -  at 283.8s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:42] {1020} INFO - iteration 239, current learner rf\n",
            "[flaml.automl: 08-01 03:36:43] {1180} INFO -  at 285.0s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:43] {1020} INFO - iteration 240, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:44] {1180} INFO -  at 286.3s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:44] {1020} INFO - iteration 241, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:46] {1180} INFO -  at 287.6s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:46] {1020} INFO - iteration 242, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:46] {1180} INFO -  at 287.7s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:46] {1020} INFO - iteration 243, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:46] {1180} INFO -  at 287.8s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:46] {1020} INFO - iteration 244, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:46] {1180} INFO -  at 287.9s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:46] {1020} INFO - iteration 245, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:46] {1180} INFO -  at 288.0s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:46] {1020} INFO - iteration 246, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:46] {1180} INFO -  at 288.1s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:46] {1020} INFO - iteration 247, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:47] {1180} INFO -  at 289.3s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:47] {1020} INFO - iteration 248, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:48] {1180} INFO -  at 289.4s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:48] {1020} INFO - iteration 249, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:48] {1180} INFO -  at 289.5s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:48] {1020} INFO - iteration 250, current learner rf\n",
            "[flaml.automl: 08-01 03:36:49] {1180} INFO -  at 290.8s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:49] {1020} INFO - iteration 251, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:49] {1180} INFO -  at 290.9s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:49] {1020} INFO - iteration 252, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:49] {1180} INFO -  at 291.0s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:49] {1020} INFO - iteration 253, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:49] {1180} INFO -  at 291.1s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:49] {1020} INFO - iteration 254, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:49] {1180} INFO -  at 291.3s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:49] {1020} INFO - iteration 255, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:50] {1180} INFO -  at 291.8s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:50] {1020} INFO - iteration 256, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:50] {1180} INFO -  at 291.9s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:50] {1020} INFO - iteration 257, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:51] {1180} INFO -  at 292.4s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:51] {1020} INFO - iteration 258, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:51] {1180} INFO -  at 292.6s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:51] {1020} INFO - iteration 259, current learner lrl1\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[flaml.automl: 08-01 03:36:51] {1180} INFO -  at 293.1s,\tbest lrl1's error=0.1815,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:51] {1020} INFO - iteration 260, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:51] {1180} INFO -  at 293.2s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:51] {1020} INFO - iteration 261, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:53] {1180} INFO -  at 294.5s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:53] {1020} INFO - iteration 262, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:53] {1180} INFO -  at 294.6s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:53] {1020} INFO - iteration 263, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:53] {1180} INFO -  at 294.7s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:53] {1020} INFO - iteration 264, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:53] {1180} INFO -  at 294.8s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:53] {1020} INFO - iteration 265, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:53] {1180} INFO -  at 295.0s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:53] {1020} INFO - iteration 266, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:54] {1180} INFO -  at 296.2s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:54] {1020} INFO - iteration 267, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:56] {1180} INFO -  at 297.5s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:56] {1020} INFO - iteration 268, current learner extra_tree\n",
            "[flaml.automl: 08-01 03:36:57] {1180} INFO -  at 298.7s,\tbest extra_tree's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:57] {1020} INFO - iteration 269, current learner rf\n",
            "[flaml.automl: 08-01 03:36:58] {1180} INFO -  at 299.8s,\tbest rf's error=0.0023,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:58] {1020} INFO - iteration 270, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:58] {1180} INFO -  at 299.9s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:58] {1020} INFO - iteration 271, current learner lgbm\n",
            "[flaml.automl: 08-01 03:36:58] {1180} INFO -  at 300.0s,\tbest lgbm's error=0.0136,\tbest extra_tree's error=0.0023\n",
            "[flaml.automl: 08-01 03:36:58] {1220} INFO - selected model: ExtraTreesClassifier(criterion='entropy', max_features=0.882500038087248,\n",
            "                     max_leaf_nodes=27, n_estimators=8, n_jobs=-1)\n",
            "[flaml.automl: 08-01 03:36:58] {970} INFO - fit succeeded\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PApZmJmwvhI",
        "outputId": "e923ba78-225a-42e4-dc71-1b2e0292c894"
      },
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best ML leaner: extra_tree\n",
            "Best hyperparmeter config: {'n_estimators': 8, 'max_features': 0.882500038087248, 'max_leaves': 27, 'criterion': 'entropy'}\n",
            "Best accuracy on validation data: 0.9977\n",
            "Training duration of best run: 1.565 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrwbAznVyb6C",
        "outputId": "cc6bc77f-cf12-4d72-ab94-8ce4f9791002"
      },
      "source": [
        "automl.model.estimator"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesClassifier(criterion='entropy', max_features=0.882500038087248,\n",
              "                     max_leaf_nodes=27, n_estimators=8, n_jobs=-1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrbJirhzyjVy"
      },
      "source": [
        "import pickle\n",
        "with open('automl.pkl', 'wb') as f:\n",
        "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZol68ueyo6E",
        "outputId": "d80ee2ef-1f26-4d7e-fd45-40b53d8add8d"
      },
      "source": [
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)\n",
        "y_pred_proba = automl.predict_proba(X_test)[:,1]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted labels ['Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'moderately polluted water'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'moderately polluted water' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'moderately polluted water' 'Good' 'Excellent' 'Excellent'\n",
            " 'moderately polluted water' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Good']\n",
            "True labels ['Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'moderately polluted water'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Good' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'moderately polluted water' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'highly polluted water' 'Good' 'Excellent' 'Excellent'\n",
            " 'moderately polluted water' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent' 'Excellent'\n",
            " 'Excellent' 'moderately polluted water']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja9dz2AXy3BV",
        "outputId": "9a6a4a0f-f883-4432-c628-4d409ebaa78a"
      },
      "source": [
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, train_loss_history = \\\n",
        "    get_output_from_log(filename=settings['log_file_name'], time_budget=60)\n",
        "\n",
        "for config in config_history:\n",
        "    print(config)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Current Learner': 'lgbm', 'Current Sample': 441, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.1, 'subsample': 1.0, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.1, 'subsample': 1.0, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 441, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 441, 'Current Hyper-parameters': {'n_estimators': 7, 'num_leaves': 4, 'min_child_samples': 18, 'learning_rate': 0.4884534146152136, 'subsample': 0.9647550813352507, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0010352743615901622, 'reg_lambda': 0.07926874541931893}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 7, 'num_leaves': 4, 'min_child_samples': 18, 'learning_rate': 0.4884534146152136, 'subsample': 0.9647550813352507, 'log_max_bin': 10, 'colsample_bytree': 1.0, 'reg_alpha': 0.0010352743615901622, 'reg_lambda': 0.07926874541931893}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 441, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 6, 'min_child_weight': 0.2620811530815948, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 6, 'min_child_weight': 0.2620811530815948, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 441, 'Current Hyper-parameters': {'n_estimators': 6, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796903}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 6, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796903}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 441, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.10422622872469292, 'learning_rate': 1.0, 'subsample': 0.8286310106576346, 'colsample_bylevel': 0.7539376453684443, 'colsample_bytree': 0.9485956837704628, 'reg_alpha': 0.0063736480220318815, 'reg_lambda': 2.33607966864803}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.10422622872469292, 'learning_rate': 1.0, 'subsample': 0.8286310106576346, 'colsample_bylevel': 0.7539376453684443, 'colsample_bytree': 0.9485956837704628, 'reg_alpha': 0.0063736480220318815, 'reg_lambda': 2.33607966864803}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 441, 'Current Hyper-parameters': {'n_estimators': 6, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6413547778096401, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496044, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796903}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 6, 'max_leaves': 5, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6413547778096401, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496044, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796903}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YYDHZxDKzCOX",
        "outputId": "a8faf7ec-a1b4-4236-8375-b24b852aa634"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMOfAHbRzGUd"
      },
      "source": [
        "from flaml.model import SKLearnEstimator\n",
        "from flaml import tune\n",
        "from rgf.sklearn import RGFClassifier, RGFRegressor\n",
        "\n",
        "\n",
        "class MyRegularizedGreedyForest(SKLearnEstimator):\n",
        "\n",
        "\n",
        "    def __init__(self, task='binary:logistic', n_jobs=1, **params):\n",
        "        '''Constructor\n",
        "        \n",
        "        Args:\n",
        "            task: A string of the task type, one of\n",
        "                'binary:logistic', 'multi:softmax', 'regression'\n",
        "            n_jobs: An integer of the number of parallel threads\n",
        "            params: A dictionary of the hyperparameter names and values\n",
        "        '''\n",
        "\n",
        "        super().__init__(task, **params)\n",
        "\n",
        "        '''task=regression for RGFRegressor; \n",
        "        binary:logistic and multiclass:softmax for RGFClassifier'''\n",
        "        if 'regression' in task:\n",
        "            self.estimator_class = RGFRegressor\n",
        "        else:\n",
        "            self.estimator_class = RGFClassifier\n",
        "# convert to int for integer hyperparameters\n",
        "        self.params = {\n",
        "            \"n_jobs\": n_jobs,\n",
        "            'max_leaf': int(params['max_leaf']),\n",
        "            'n_iter': int(params['n_iter']),\n",
        "            'n_tree_search': int(params['n_tree_search']),\n",
        "            'opt_interval': int(params['opt_interval']),\n",
        "            'learning_rate': params['learning_rate'],\n",
        "            'min_samples_leaf': int(params['min_samples_leaf'])\n",
        "        }    \n",
        "\n",
        "    @classmethod\n",
        "    def search_space(cls, data_size, task):\n",
        "        '''[required method] search space\n",
        "\n",
        "        Returns:\n",
        "            A dictionary of the search space. \n",
        "            Each key is the name of a hyperparameter, and value is a dict with\n",
        "                its domain and init_value (optional), cat_hp_cost (optional) \n",
        "                e.g., \n",
        "                {'domain': tune.randint(lower=1, upper=10), 'init_value': 1}\n",
        "        '''\n",
        "        space = {        \n",
        "            'max_leaf': {'domain': tune.lograndint(lower=4, upper=data_size), 'init_value': 4, 'low_cost_init_value': 4},\n",
        "            'n_iter': {'domain': tune.lograndint(lower=1, upper=data_size), 'init_value': 1, 'low_cost_init_value': 1},\n",
        "            'n_tree_search': {'domain': tune.lograndint(lower=1, upper=32768), 'init_value': 1, 'low_cost_init_value': 1},\n",
        "            'opt_interval': {'domain': tune.lograndint(lower=1, upper=10000), 'init_value': 100},\n",
        "            'learning_rate': {'domain': tune.loguniform(lower=0.01, upper=20.0)},\n",
        "            'min_samples_leaf': {'domain': tune.lograndint(lower=1, upper=20), 'init_value': 20},\n",
        "        }\n",
        "        return space\n",
        "\n",
        "    @classmethod\n",
        "    def size(cls, config):\n",
        "        '''[optional method] memory size of the estimator in bytes\n",
        "        \n",
        "        Args:\n",
        "            config - the dict of the hyperparameter config\n",
        "\n",
        "        Returns:\n",
        "            A float of the memory size required by the estimator to train the\n",
        "            given config\n",
        "        '''\n",
        "        max_leaves = int(round(config['max_leaf']))\n",
        "        n_estimators = int(round(config['n_iter']))\n",
        "        return (max_leaves * 3 + (max_leaves - 1) * 4 + 1.0) * n_estimators * 8\n",
        "\n",
        "    @classmethod\n",
        "    def cost_relative2lgbm(cls):\n",
        "        '''[optional method] relative cost compared to lightgbm\n",
        "        '''\n",
        "        return 1.0"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25hckysNzZ35"
      },
      "source": [
        "automl = AutoML()\n",
        "automl.add_learner(learner_name='RGF', learner_class=MyRegularizedGreedyForest)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFwTEEJqzi1d",
        "outputId": "23059655-c22b-4390-8f5a-3400524a5f94"
      },
      "source": [
        "settings = {\n",
        "    \"time_budget\": 60,  # total running time in seconds\n",
        "    \"metric\": 'accuracy', \n",
        "    \"estimator_list\": ['RGF', 'lgbm', 'rf', 'xgboost'],  # list of ML learners\n",
        "    \"task\": 'classification',  # task type    \n",
        "    \"log_training_metric\": True,  # whether to log training metric\n",
        "}\n",
        "\n",
        "'''The main flaml automl API'''\n",
        "automl.fit(X_train = X_train, y_train = y_train, **settings)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[flaml.automl: 08-01 03:43:41] {913} INFO - Evaluation method: cv\n",
            "[flaml.automl: 08-01 03:43:41] {509} INFO - class 1 augmented from 16 to 32\n",
            "[flaml.automl: 08-01 03:43:41] {509} INFO - class 2 augmented from 1 to 20\n",
            "[flaml.automl: 08-01 03:43:41] {509} INFO - class 3 augmented from 3 to 21\n",
            "[flaml.automl: 08-01 03:43:41] {607} INFO - Using StratifiedKFold\n",
            "[flaml.automl: 08-01 03:43:41] {934} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl: 08-01 03:43:41] {954} INFO - List of ML learners in AutoML Run: ['RGF', 'lgbm', 'rf', 'xgboost']\n",
            "[flaml.automl: 08-01 03:43:41] {1020} INFO - iteration 0, current learner RGF\n",
            "[flaml.automl: 08-01 03:43:42] {1180} INFO -  at 1.4s,\tbest RGF's error=0.0680,\tbest RGF's error=0.0680\n",
            "[flaml.automl: 08-01 03:43:42] {1020} INFO - iteration 1, current learner RGF\n",
            "[flaml.automl: 08-01 03:43:43] {1180} INFO -  at 2.7s,\tbest RGF's error=0.0680,\tbest RGF's error=0.0680\n",
            "[flaml.automl: 08-01 03:43:43] {1020} INFO - iteration 2, current learner RGF\n",
            "[flaml.automl: 08-01 03:43:45] {1180} INFO -  at 4.0s,\tbest RGF's error=0.0680,\tbest RGF's error=0.0680\n",
            "[flaml.automl: 08-01 03:43:45] {1020} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:45] {1180} INFO -  at 4.0s,\tbest lgbm's error=0.1655,\tbest RGF's error=0.0680\n",
            "[flaml.automl: 08-01 03:43:45] {1020} INFO - iteration 4, current learner RGF\n",
            "[flaml.automl: 08-01 03:43:46] {1180} INFO -  at 5.3s,\tbest RGF's error=0.0680,\tbest RGF's error=0.0680\n",
            "[flaml.automl: 08-01 03:43:46] {1020} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:46] {1180} INFO -  at 5.4s,\tbest lgbm's error=0.1655,\tbest RGF's error=0.0680\n",
            "[flaml.automl: 08-01 03:43:46] {1020} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:46] {1180} INFO -  at 5.4s,\tbest lgbm's error=0.0340,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:43:46] {1020} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:46] {1180} INFO -  at 5.5s,\tbest lgbm's error=0.0340,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:43:46] {1020} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:46] {1180} INFO -  at 5.5s,\tbest lgbm's error=0.0340,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:43:46] {1020} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:46] {1180} INFO -  at 5.6s,\tbest lgbm's error=0.0340,\tbest lgbm's error=0.0340\n",
            "[flaml.automl: 08-01 03:43:46] {1020} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:46] {1180} INFO -  at 5.7s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:46] {1020} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:47] {1180} INFO -  at 5.7s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:47] {1020} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:47] {1180} INFO -  at 5.8s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:47] {1020} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:47] {1180} INFO -  at 5.9s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:47] {1020} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:47] {1180} INFO -  at 5.9s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:47] {1020} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:47] {1180} INFO -  at 6.0s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:47] {1020} INFO - iteration 16, current learner RGF\n",
            "[flaml.automl: 08-01 03:43:48] {1180} INFO -  at 7.3s,\tbest RGF's error=0.0680,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:48] {1020} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:48] {1180} INFO -  at 7.4s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:48] {1020} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:48] {1180} INFO -  at 7.4s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:48] {1020} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:48] {1180} INFO -  at 7.5s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:48] {1020} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:48] {1180} INFO -  at 7.6s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:48] {1020} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:49] {1180} INFO -  at 7.7s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:49] {1020} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:49] {1180} INFO -  at 7.8s,\tbest lgbm's error=0.0182,\tbest lgbm's error=0.0182\n",
            "[flaml.automl: 08-01 03:43:49] {1020} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:49] {1180} INFO -  at 7.9s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:49] {1020} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:49] {1180} INFO -  at 8.0s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:49] {1020} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:49] {1180} INFO -  at 8.1s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:49] {1020} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:49] {1180} INFO -  at 8.2s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:49] {1020} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:49] {1180} INFO -  at 8.3s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:49] {1020} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:49] {1180} INFO -  at 8.4s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:49] {1020} INFO - iteration 29, current learner RGF\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 9.7s,\tbest RGF's error=0.0680,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 9.8s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 9.9s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 10.1s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 10.2s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 10.3s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 10.4s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 36, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 10.5s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:51] {1180} INFO -  at 10.6s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:51] {1020} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:52] {1180} INFO -  at 10.7s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:52] {1020} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:52] {1180} INFO -  at 10.9s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:52] {1020} INFO - iteration 40, current learner RGF\n",
            "[flaml.automl: 08-01 03:43:53] {1180} INFO -  at 12.2s,\tbest RGF's error=0.0680,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:53] {1020} INFO - iteration 41, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:53] {1180} INFO -  at 12.3s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:53] {1020} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:53] {1180} INFO -  at 12.5s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:53] {1020} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:53] {1180} INFO -  at 12.5s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:53] {1020} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:53] {1180} INFO -  at 12.6s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:53] {1020} INFO - iteration 45, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:54] {1180} INFO -  at 12.7s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:54] {1020} INFO - iteration 46, current learner RGF\n",
            "[flaml.automl: 08-01 03:43:55] {1180} INFO -  at 14.0s,\tbest RGF's error=0.0680,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:55] {1020} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:55] {1180} INFO -  at 14.1s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:55] {1020} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:55] {1180} INFO -  at 14.2s,\tbest xgboost's error=0.0409,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:55] {1020} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:55] {1180} INFO -  at 14.3s,\tbest xgboost's error=0.0409,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:55] {1020} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:55] {1180} INFO -  at 14.4s,\tbest xgboost's error=0.0318,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:55] {1020} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:55] {1180} INFO -  at 14.4s,\tbest xgboost's error=0.0227,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:55] {1020} INFO - iteration 52, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:55] {1180} INFO -  at 14.5s,\tbest xgboost's error=0.0159,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:55] {1020} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:55] {1180} INFO -  at 14.6s,\tbest lgbm's error=0.0136,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:55] {1020} INFO - iteration 54, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 14.7s,\tbest xgboost's error=0.0159,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 14.9s,\tbest xgboost's error=0.0159,\tbest lgbm's error=0.0136\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 15.0s,\tbest xgboost's error=0.0068,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 57, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 15.1s,\tbest xgboost's error=0.0068,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 15.2s,\tbest xgboost's error=0.0068,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 59, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 15.3s,\tbest xgboost's error=0.0068,\tbest xgboost's error=0.0068\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 15.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 15.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:56] {1180} INFO -  at 15.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:56] {1020} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 15.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 15.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 15.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 16.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 67, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 16.1s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 16.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 69, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 16.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 16.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 16.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 16.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:57] {1180} INFO -  at 16.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:57] {1020} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 16.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 16.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 76, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 17.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 17.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 17.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 79, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 17.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 17.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 17.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 17.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:58] {1180} INFO -  at 17.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:58] {1020} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 17.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 85, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 17.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 18.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 18.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 18.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 18.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 18.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 91, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 18.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 92, current learner xgboost\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 18.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 93, current learner lgbm\n",
            "[flaml.automl: 08-01 03:43:59] {1180} INFO -  at 18.7s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:43:59] {1020} INFO - iteration 94, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:00] {1180} INFO -  at 18.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:00] {1020} INFO - iteration 95, current learner rf\n",
            "[flaml.automl: 08-01 03:44:01] {1180} INFO -  at 20.4s,\tbest rf's error=0.0567,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:01] {1020} INFO - iteration 96, current learner rf\n",
            "[flaml.automl: 08-01 03:44:03] {1180} INFO -  at 22.1s,\tbest rf's error=0.0386,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:03] {1020} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:03] {1180} INFO -  at 22.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:03] {1020} INFO - iteration 98, current learner rf\n",
            "[flaml.automl: 08-01 03:44:05] {1180} INFO -  at 23.8s,\tbest rf's error=0.0386,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:05] {1020} INFO - iteration 99, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:05] {1180} INFO -  at 23.9s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:05] {1020} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:05] {1180} INFO -  at 24.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:05] {1020} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:05] {1180} INFO -  at 24.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:05] {1020} INFO - iteration 102, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:06] {1180} INFO -  at 25.4s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:06] {1020} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:06] {1180} INFO -  at 25.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:06] {1020} INFO - iteration 104, current learner rf\n",
            "[flaml.automl: 08-01 03:44:08] {1180} INFO -  at 27.3s,\tbest rf's error=0.0340,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:08] {1020} INFO - iteration 105, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:08] {1180} INFO -  at 27.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:08] {1020} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:08] {1180} INFO -  at 27.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:08] {1020} INFO - iteration 107, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:08] {1180} INFO -  at 27.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:08] {1020} INFO - iteration 108, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:08] {1180} INFO -  at 27.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:08] {1020} INFO - iteration 109, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:09] {1180} INFO -  at 27.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:09] {1020} INFO - iteration 110, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:10] {1180} INFO -  at 29.0s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:10] {1020} INFO - iteration 111, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:10] {1180} INFO -  at 29.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:10] {1020} INFO - iteration 112, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:10] {1180} INFO -  at 29.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:10] {1020} INFO - iteration 113, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:10] {1180} INFO -  at 29.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:10] {1020} INFO - iteration 114, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:10] {1180} INFO -  at 29.4s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:10] {1020} INFO - iteration 115, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:10] {1180} INFO -  at 29.5s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:10] {1020} INFO - iteration 116, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:10] {1180} INFO -  at 29.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:10] {1020} INFO - iteration 117, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:11] {1180} INFO -  at 29.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:11] {1020} INFO - iteration 118, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:12] {1180} INFO -  at 31.0s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:12] {1020} INFO - iteration 119, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:12] {1180} INFO -  at 31.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:12] {1020} INFO - iteration 120, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:12] {1180} INFO -  at 31.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:12] {1020} INFO - iteration 121, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:12] {1180} INFO -  at 31.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:12] {1020} INFO - iteration 122, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:12] {1180} INFO -  at 31.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:12] {1020} INFO - iteration 123, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:12] {1180} INFO -  at 31.5s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:12] {1020} INFO - iteration 124, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:14] {1180} INFO -  at 32.8s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:14] {1020} INFO - iteration 125, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:15] {1180} INFO -  at 34.0s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:15] {1020} INFO - iteration 126, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:16] {1180} INFO -  at 35.4s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:16] {1020} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:16] {1180} INFO -  at 35.5s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:16] {1020} INFO - iteration 128, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:16] {1180} INFO -  at 35.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:16] {1020} INFO - iteration 129, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:16] {1180} INFO -  at 35.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:16] {1020} INFO - iteration 130, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:17] {1180} INFO -  at 35.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:17] {1020} INFO - iteration 131, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:17] {1180} INFO -  at 35.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:17] {1020} INFO - iteration 132, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:17] {1180} INFO -  at 36.0s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:17] {1020} INFO - iteration 133, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:17] {1180} INFO -  at 36.1s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:17] {1020} INFO - iteration 134, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:17] {1180} INFO -  at 36.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:17] {1020} INFO - iteration 135, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:17] {1180} INFO -  at 36.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:17] {1020} INFO - iteration 136, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:17] {1180} INFO -  at 36.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:17] {1020} INFO - iteration 137, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 37.8s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 138, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 37.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 139, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 38.0s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 140, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 38.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 141, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 38.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 142, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 38.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 143, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 38.3s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 144, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 38.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 145, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:19] {1180} INFO -  at 38.5s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:19] {1020} INFO - iteration 146, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:21] {1180} INFO -  at 39.9s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:21] {1020} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:21] {1180} INFO -  at 40.0s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:21] {1020} INFO - iteration 148, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:22] {1180} INFO -  at 41.3s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:22] {1020} INFO - iteration 149, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:22] {1180} INFO -  at 41.4s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:22] {1020} INFO - iteration 150, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:22] {1180} INFO -  at 41.5s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:22] {1020} INFO - iteration 151, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:22] {1180} INFO -  at 41.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:22] {1020} INFO - iteration 152, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:22] {1180} INFO -  at 41.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:22] {1020} INFO - iteration 153, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:24] {1180} INFO -  at 43.0s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:24] {1020} INFO - iteration 154, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:25] {1180} INFO -  at 44.3s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:25] {1020} INFO - iteration 155, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:25] {1180} INFO -  at 44.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:25] {1020} INFO - iteration 156, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:25] {1180} INFO -  at 44.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:25] {1020} INFO - iteration 157, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:25] {1180} INFO -  at 44.6s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:25] {1020} INFO - iteration 158, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:25] {1180} INFO -  at 44.7s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:25] {1020} INFO - iteration 159, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 44.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 160, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 44.9s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 161, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 45.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 162, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 45.1s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 163, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 45.2s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 164, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 45.3s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 165, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 45.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 166, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 45.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 167, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 45.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 168, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:26] {1180} INFO -  at 45.6s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:26] {1020} INFO - iteration 169, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:28] {1180} INFO -  at 46.9s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:28] {1020} INFO - iteration 170, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:29] {1180} INFO -  at 48.3s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:29] {1020} INFO - iteration 171, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:29] {1180} INFO -  at 48.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:29] {1020} INFO - iteration 172, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:29] {1180} INFO -  at 48.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:29] {1020} INFO - iteration 173, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:29] {1180} INFO -  at 48.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:29] {1020} INFO - iteration 174, current learner rf\n",
            "[flaml.automl: 08-01 03:44:31] {1180} INFO -  at 50.3s,\tbest rf's error=0.0340,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:31] {1020} INFO - iteration 175, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:31] {1180} INFO -  at 50.4s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:31] {1020} INFO - iteration 176, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:31] {1180} INFO -  at 50.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:31] {1020} INFO - iteration 177, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:31] {1180} INFO -  at 50.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:31] {1020} INFO - iteration 178, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:32] {1180} INFO -  at 50.8s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:32] {1020} INFO - iteration 179, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:32] {1180} INFO -  at 50.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:32] {1020} INFO - iteration 180, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:32] {1180} INFO -  at 51.0s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:32] {1020} INFO - iteration 181, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:32] {1180} INFO -  at 51.1s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:32] {1020} INFO - iteration 182, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:33] {1180} INFO -  at 52.5s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:33] {1020} INFO - iteration 183, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:33] {1180} INFO -  at 52.6s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:33] {1020} INFO - iteration 184, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:34] {1180} INFO -  at 52.7s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:34] {1020} INFO - iteration 185, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:34] {1180} INFO -  at 52.8s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:34] {1020} INFO - iteration 186, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:34] {1180} INFO -  at 52.9s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:34] {1020} INFO - iteration 187, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:35] {1180} INFO -  at 54.2s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:35] {1020} INFO - iteration 188, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:35] {1180} INFO -  at 54.3s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:35] {1020} INFO - iteration 189, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:35] {1180} INFO -  at 54.5s,\tbest xgboost's error=0.0045,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:35] {1020} INFO - iteration 190, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:35] {1180} INFO -  at 54.6s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0045\n",
            "[flaml.automl: 08-01 03:44:35] {1020} INFO - iteration 191, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:36] {1180} INFO -  at 54.8s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:36] {1020} INFO - iteration 192, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:36] {1180} INFO -  at 54.9s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:36] {1020} INFO - iteration 193, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:36] {1180} INFO -  at 55.1s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:36] {1020} INFO - iteration 194, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:36] {1180} INFO -  at 55.2s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:36] {1020} INFO - iteration 195, current learner lgbm\n",
            "[flaml.automl: 08-01 03:44:36] {1180} INFO -  at 55.3s,\tbest lgbm's error=0.0136,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:36] {1020} INFO - iteration 196, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:36] {1180} INFO -  at 55.5s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:36] {1020} INFO - iteration 197, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:36] {1180} INFO -  at 55.6s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:36] {1020} INFO - iteration 198, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:37] {1180} INFO -  at 55.8s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:37] {1020} INFO - iteration 199, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:37] {1180} INFO -  at 55.9s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:37] {1020} INFO - iteration 200, current learner RGF\n",
            "[flaml.automl: 08-01 03:44:38] {1180} INFO -  at 57.3s,\tbest RGF's error=0.0680,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:38] {1020} INFO - iteration 201, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:38] {1180} INFO -  at 57.4s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:38] {1020} INFO - iteration 202, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:38] {1180} INFO -  at 57.6s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:38] {1020} INFO - iteration 203, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:39] {1180} INFO -  at 57.8s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:39] {1020} INFO - iteration 204, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:39] {1180} INFO -  at 57.9s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:39] {1020} INFO - iteration 205, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:39] {1180} INFO -  at 58.0s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:39] {1020} INFO - iteration 206, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:39] {1180} INFO -  at 58.2s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:39] {1020} INFO - iteration 207, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:39] {1180} INFO -  at 58.5s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:39] {1020} INFO - iteration 208, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:39] {1180} INFO -  at 58.6s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:39] {1020} INFO - iteration 209, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:40] {1180} INFO -  at 58.7s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:40] {1020} INFO - iteration 210, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:40] {1180} INFO -  at 59.0s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:40] {1020} INFO - iteration 211, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:40] {1180} INFO -  at 59.2s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:40] {1020} INFO - iteration 212, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:40] {1180} INFO -  at 59.3s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:40] {1020} INFO - iteration 213, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:40] {1180} INFO -  at 59.4s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:40] {1020} INFO - iteration 214, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:40] {1180} INFO -  at 59.6s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:40] {1020} INFO - iteration 215, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:41] {1180} INFO -  at 59.8s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:41] {1020} INFO - iteration 216, current learner xgboost\n",
            "[flaml.automl: 08-01 03:44:41] {1180} INFO -  at 60.0s,\tbest xgboost's error=0.0022,\tbest xgboost's error=0.0022\n",
            "[flaml.automl: 08-01 03:44:41] {1220} INFO - selected model: XGBClassifier(colsample_bylevel=0.9564659852127502,\n",
            "              colsample_bytree=0.8082937211691524, grow_policy='lossguide',\n",
            "              learning_rate=0.5856946902963877, max_depth=0, max_leaves=4,\n",
            "              min_child_weight=0.6227855438873857, n_estimators=18, n_jobs=-1,\n",
            "              objective='multi:softprob', reg_alpha=0.0017360301887211303,\n",
            "              reg_lambda=0.8889114692287184, subsample=1.0, tree_method='hist',\n",
            "              use_label_encoder=False, verbosity=0)\n",
            "[flaml.automl: 08-01 03:44:41] {970} INFO - fit succeeded\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fd5lH_Vzlr5",
        "outputId": "4d274a10-676a-4a9c-b593-b623adcf8ef2"
      },
      "source": [
        "print('flaml accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flaml accuracy = 0.9690721649484536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVR3WsDH0TBd"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgbm = LGBMClassifier()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03OVcM6n0Vsk",
        "outputId": "3fda9ff9-7125-4004-fc54-a118cd24cda6"
      },
      "source": [
        "lgbm.fit(X_train, y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETTDna0u0YJZ",
        "outputId": "f323819d-1531-493d-fee6-e2c34e446129"
      },
      "source": [
        "y_pred = lgbm.predict(X_test)\n",
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('default lgbm accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default lgbm accuracy = 0.9690721649484536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZE9TURb0bPy"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PYERI660eOS",
        "outputId": "16af0c6e-0ff2-4ad9-c94b-7e2d88ca2dd6"
      },
      "source": [
        "xgb.fit(X_train, y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(objective='multi:softprob')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRyno-rU0gpz",
        "outputId": "1716239a-c57d-42b1-9aa0-8a85fbc20832"
      },
      "source": [
        "y_pred = xgb.predict(X_test)\n",
        "from flaml.ml import sklearn_metric_loss_score\n",
        "print('default xgboost accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default xgboost accuracy = 0.9484536082474226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdifihGq0kbj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}